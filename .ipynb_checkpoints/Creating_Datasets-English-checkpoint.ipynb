{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets for \"A Doll's House\" by Ibsen\n",
    "\n",
    "## 1. Isolating spoken word from stage directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the file. Using regex to remove the stage directions from the play script. All stage directions exist within parentheses, both within and outside spoken text. Then, regex is added to match a pattern for a single character, \"Mrs. Linde,\" and combine her name into a single word. This helps with the parsing of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filein = open('dollshouse.txt', 'r')\n",
    "full_text = filein.read()\n",
    "filein.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken = re.sub(r'\\((.|\\n)+?\\)', '', full_text)\n",
    "linda_pattern = re.compile(r'^Mrs\\. Linde\\.', re.MULTILINE)\n",
    "spoken = re.sub(linda_pattern, 'MrsLinde.', spoken)\n",
    "#print(spoken)\n",
    "split_text = spoken.split(\"\\n\\n\")\n",
    "#print(split_text)\n",
    "\n",
    "#print(split_text.index(\"\\nACT I\"))  <--- finding the first line of the script\n",
    "\n",
    "spoken_text = split_text[9:] # begins at first line of script\n",
    "#print(spoken_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and lowercasing the play script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doll_cleaned = []\n",
    "for line in spoken_text:\n",
    "    cleanedline = line\n",
    "    for p in string.punctuation:\n",
    "        cleanedline = cleanedline.replace(p,\" \").lower()\n",
    "    doll_cleaned.append(cleanedline.lower()+\"\\n\")\n",
    "#print(doll_cleaned)\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# tokens = word_tokenize(text)\n",
    "# # remove all tokens that are not alphabetic\n",
    "# words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "# there's some weird punctuation happening in this script (i.e. Torvald--?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the names and associated lines for each character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the names of each character that speaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "\n",
    "for speech in doll_cleaned:\n",
    "    character_line = speech.split()\n",
    "    #print(speech)\n",
    "    if len(character_line) > 1:\n",
    "        # splits each speech into words\n",
    "        #print(\"hello from the if statement\")\n",
    "        character_name = character_line[0] + \" \" # grabs first word, which will always be name of character speaking\n",
    "        name.append(character_name)\n",
    "        #name += character_name\n",
    "        \n",
    "#print(name)\n",
    "#print(len(updated_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the speech content of each character that speaks. Their name will be included within this section. Names will be filtered out when getting the counts for each word, so the inclusion of the name here is inconsequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_speech_list = []\n",
    "for speech in doll_cleaned:\n",
    "    if len(speech) > 1:\n",
    "        character_speech_list.append(speech.strip())\n",
    "#         character_line = speech.split()\n",
    "#         #character_speech = character_line[1:]\n",
    "        #character_speech_list+=speech\n",
    "\n",
    "\n",
    "#print(character_speech_list)\n",
    "# print(len(character_speech_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing out to a .csv file. The output file will contain 2 columns (character name and the associated line). The output file will have 1288 rows containing textual data. While the character name column contains repeated values (the cast of characters, which will eventually become the class when applying logistic regression), the associated line column should contain entirely unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['character_name', 'character_speech']\n",
    "\n",
    "with open('characters_and_speeches-English.csv', 'w', newline='') as outfile:\n",
    "    csvout = csv.writer(outfile)\n",
    "    csvout.writerow(headers)\n",
    "    csvout.writerows(zip(name, character_speech_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_name</th>\n",
       "      <th>character_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nora</td>\n",
       "      <td>nora  hide the christmas tree carefully  helen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>porter</td>\n",
       "      <td>porter  sixpence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nora</td>\n",
       "      <td>nora  there is a shilling  no  keep the change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>helmer</td>\n",
       "      <td>helmer   is that my little lark twittering out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nora</td>\n",
       "      <td>nora   yes  it is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character_name                                   character_speech\n",
       "0          nora   nora  hide the christmas tree carefully  helen...\n",
       "1        porter                                    porter  sixpence\n",
       "2          nora   nora  there is a shilling  no  keep the change...\n",
       "3        helmer   helmer   is that my little lark twittering out...\n",
       "4          nora                                   nora   yes  it is"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = pd.read_csv(\"characters_and_speeches-English.csv\")\n",
    "english_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting the counts for each word in the playscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the counts of each word in the play script. I still need to create a \"stop list\" for the subject-based words. And then the following script will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_words = []\n",
    "for line in character_speech_list:\n",
    "    split_character = line.split()\n",
    "    character_words.append(split_character)\n",
    "    #character_words += split_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topical_words = ['torvald', 'helmer', 'nora', 'rank', 'linde', 'mrs', 'nils', 'krogstad', 'anne', 's', 't', 'mrslinde', \n",
    "              'christine', 'emmy', 'husband', 'children', 'father', 'mother', 'man', 'doctor', 'home', \n",
    "              'money', 'letter', 'poor', 'papa', 'christmas', 'live', 'love', 'tomorrow', 'evening', 'happy', \n",
    "              'impossible', 'himself', 'herself', 'woman', 'sake', 'darling', 'mr', 'tonight', 'darling', 'fancy', \n",
    "              'goodnight', 'fun', 'ma', 'child', 'goodbye', 'yesterday', 'helen', 'death', 'forgotten', 'reason', \n",
    "              'death', 'champagne', 'loved', 'tarantella', 'tree', 'promise', 'forgiven', 'anne', 'doll', 'skylark', \n",
    "              'lawyer', 'paper', 'brother', 'sister', 'morality', 'punished', 'destroyed', 'mistress', 'wedlock', 'liar',\n",
    "                'nurse', 'wife', 'bank', 'maid', 'family', 'jealous', 'mamma', 'women', 'men', 'maiden', 'office']\n",
    "\n",
    "# will need a better way of cleaning punctuation so apostrophe's and hyphenates do not get erased\n",
    "#print(character_words)\n",
    "\n",
    "word_counts = Counter()\n",
    "for line in character_words:\n",
    "    for word in line:\n",
    "        if word not in topical_words:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "#print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
