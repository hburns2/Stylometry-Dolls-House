{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets for \"A Doll's House\" by Ibsen\n",
    "\n",
    "## 1. Isolating spoken word from stage directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing the English code to work with the Bokm책l version of the play script. \n",
    "**NOTE:** I have not yet finished cleaning the Bokm책l version of the play script. Everything in this doc is a skeleton and will be altered as the actual text I plan on using is finalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filein = open('Et_dukkehjem_first_edition_uncleaned.txt', 'r')  # this will change once I finish cleaning the Bokm책l version\n",
    "full_text = filein.read()\n",
    "filein.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken = re.sub(r'\\((.|\\n)+?\\)', '', full_text)\n",
    "linda_pattern = re.compile(r'^Fru Linde\\.', re.MULTILINE)\n",
    "spoken = re.sub(linda_pattern, 'FruLinde.', spoken)\n",
    "#print(spoken)\n",
    "split_text = spoken.split(\"\\n\\n\")\n",
    "#print(split_text)\n",
    "\n",
    "#print(split_text.index(\"\\nACT I\"))\n",
    "\n",
    "spoken_text = split_text[9:] # begins at first line of script\n",
    "#print(spoken_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and lowercasing the play script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doll_cleaned = []\n",
    "for line in spoken_text:\n",
    "    cleanedline = line\n",
    "    for p in string.punctuation:\n",
    "        cleanedline = cleanedline.replace(p,\" \").lower()\n",
    "    doll_cleaned.append(cleanedline.lower()+\"\\n\")\n",
    "#print(doll_cleaned)\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# tokens = word_tokenize(text)\n",
    "# # remove all tokens that are not alphabetic\n",
    "# words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "# there's some weird punctuation happening in this script (i.e. Torvald--?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the names and associated lines for each character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the names of each character that speaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "\n",
    "for speech in doll_cleaned:\n",
    "    character_line = speech.split()\n",
    "    #print(speech)\n",
    "    if len(character_line) > 1:\n",
    "        # splits each speech into words\n",
    "        #print(\"hello from the if statement\")\n",
    "        character_name = character_line[0] + \" \" # grabs first word, which will always be name of character speaking\n",
    "        name.append(character_name)\n",
    "        #name += character_name\n",
    "        \n",
    "#print(name)\n",
    "#print(len(updated_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the speech content of each character that speaks, minus their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_speech_list = []\n",
    "for speech in doll_cleaned:\n",
    "    if len(speech) > 1:\n",
    "        character_speech_list.append(speech)\n",
    "#         character_line = speech.split()\n",
    "#         #character_speech = character_line[1:]\n",
    "        #character_speech_list+=speech\n",
    "\n",
    "\n",
    "#print(character_speech_list)\n",
    "# print(len(character_speech_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing out to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['character_name', 'character_speech']\n",
    "\n",
    "with open('characters_and_speeches-Bokm책l.csv', 'w', newline='') as outfile:\n",
    "    csvout = csv.writer(outfile)\n",
    "    csvout.writerow(headers)\n",
    "    csvout.writerows(zip(name, character_speech_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting the counts for each word in the playscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the counts of each word in the play script. I still need to create a \"stop list\" for the subject-based words. And then the following script will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_words = []\n",
    "for line in character_speech_list:\n",
    "    split_character = line.split()\n",
    "    character_words.append(split_character)\n",
    "    #character_words += split_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topical_words = [''] # will need to add words once cleaning is complete\n",
    "\n",
    "# will need a better way of cleaning punctuation so apostrophe's and hyphenates do not get erased\n",
    "#print(character_words)\n",
    "\n",
    "word_counts = Counter()\n",
    "for line in character_words:\n",
    "    for word in line:\n",
    "        if word not in topical_words:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "#print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
